{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be used to print accuracies.\n",
    "\n",
    "def print_accuracy(path, att_type):\n",
    "\n",
    "    with open(path + '/evaluate.json', 'r') as evaluate:\n",
    "        data = evaluate.read()\n",
    "\n",
    "    obj = json.loads(data)\n",
    "\n",
    "    print(att_type + \" accuracy: \" + str(obj['accuracy']))\n",
    "    \n",
    "    \n",
    "def get_path_and_print_acc(datasetName):\n",
    "    raw_path = check_output('./get_accuracy.sh '+datasetName, shell=True)\n",
    "    paths = {}\n",
    "\n",
    "    sep = raw_path.splitlines()\n",
    "    paths['none'] = str(sep[0])[2:-1]\n",
    "    paths['tanh'] = str(sep[1])[2:-1]\n",
    "    paths['dot'] = str(sep[2])[2:-1]\n",
    "\n",
    "    print(datasetName)\n",
    "\n",
    "    print_accuracy(paths['none'], 'none')\n",
    "    print_accuracy(paths['tanh'], 'tanh')\n",
    "    print_accuracy(paths['dot'], 'dot')\n",
    "    print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention:** outputs of the running scripts are found in the console on which the notebook is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to preprocess the datasets for the experiments on the original paper's setup. Notice the SNLI dataset might take a while, and takes up some disk space; feel free to interrupt the cell when the other datasets are done (see console output) if you just want to focus on the other tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./preprocess_datasets.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, it will be possible to run the experiments on the original codebase.\n",
    "Each cell regards a different dataset.\n",
    "\n",
    "**IMPORTANT**: In case manual checking is needed, results in the form of accuracy (and other metrics) will be found in the `outputs/<dataset_name>/lstm+<attention_type>/<current_time>/evaluate.json` files. **Please notice** that because of how the original code was structured, both the \"no attention\" and the \"tanh\" attention results will be in the folder called \"lstm+tanh\". The results of the \"no attention\" tests will be simply those with the latest timestamp. Sorry for the inconvience.\n",
    "\n",
    "Please update the permissions for the bash scripts in case they are not executable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute to run the IMDB experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./imdb_tests.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path_and_print_acc('imdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute to run the SST experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./sst_tests.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path_and_print_acc('sst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute to run the AgNews experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./agnews_tests.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path_and_print_acc('agnews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute to run the 20News experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./20news_tests.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path_and_print_acc('20News_sports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute to run the bAbI 1 experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./babi1_tests.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path_and_print_acc('babi_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute to run the SNLI experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./snli_tests.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path_and_print_acc('snli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2seq\n",
    "\n",
    "Run the autoencoder experiments, both with and without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./NMT_tests_auto.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print both the BLEU scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./NMT/eng_bleu_att.txt\",\"r\")\n",
    "print('BLEU of autoencoder with attention: ', end='')\n",
    "print(f.read())\n",
    "f.close()\n",
    "\n",
    "f = open(\"./NMT/eng_bleu_uni.txt\",\"r\")\n",
    "print('BLEU of autoencoder without attention: ', end='')\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize violin plots for autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"./NMT/eng2eng_permutation_exp.png\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img = mpimg.imread(\"./NMT/avg_aggr_eng2eng_permutation_exp.png\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img = mpimg.imread(\"./NMT/max_aggr_eng2eng_permutation_exp.png\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the NMT experiments, both with and without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call(\"./NMT_tests_fra.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print both the BLEU scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./NMT/fra_bleu_att.txt\",\"r\")\n",
    "print('BLEU of fra->eng model with attention: ', end='')\n",
    "print(f.read())\n",
    "f.close()\n",
    "\n",
    "f = open(\"./NMT/fra_bleu_uni.txt\",\"r\")\n",
    "print('BLEU of fra->eng model without attention: ', end='')\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize violin plots for NMT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"./NMT/fra2eng_permutation_exp.png\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img = mpimg.imread(\"./NMT/avg_aggr_fra2eng_permutation_exp.png\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img = mpimg.imread(\"./NMT/max_aggr_fra2eng_permutation_exp.png\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
